{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c4b8082",
   "metadata": {},
   "source": [
    "# Basics of Prompt Engineering and In-Context Learning\n",
    "* **Created by:** Eric Martinez\n",
    "* **For:** 3351 - AI-Powered Applications\n",
    "* **At:** University of Texas Rio-Grande Valley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd32fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=os.environ.get(\"OPENAI_API_BASE\"),\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "def completion(prompt, max_tokens=None, temperature=0):\n",
    "    completion = client.completions.create(\n",
    "      model=\"gpt-3.5-turbo-instruct\",\n",
    "      prompt=prompt,\n",
    "      max_tokens=max_tokens,\n",
    "      temperature=temperature\n",
    "    )\n",
    "    return completion.choices[0].text.strip()\n",
    "\n",
    "def chat_completion(message, model=\"gpt-3.5-turbo\", prompt=None, temperature=0):\n",
    "    # Initialize the messages list\n",
    "    messages = []\n",
    "    \n",
    "    # Add the prompt to the messages list\n",
    "    if prompt is not None:\n",
    "        messages += [{\"role\": \"system\", \"content\": prompt}]\n",
    "    \n",
    "    # Add the user's message to the messages list\n",
    "    messages += [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    # Make an API call to the OpenAI ChatCompletion endpoint with the model and messages\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    # Extract and return the AI's response from the API response\n",
    "    return completion.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7e49d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Prompt Engineering?\n",
    "- Not actual 'engineering'\n",
    "- The skills and process of designing, refining, and evaluating prompts to improve interactions with LLMs\n",
    "- Under this umbrella are many 'design patterns' that have emerged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dcea1d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Challenges of Prompt Engineering\n",
    "- Everything must be text\n",
    "- There is a limit to the amount of tokens that can be used (context length) for each model\n",
    "- Even with more context length, models may not be able to adequetly use it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273ec93b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Context Length of Popular Models\n",
    "- gpt-4: 8k tokens\n",
    "- gpt-4-32k: 32k tokens\n",
    "- gpt-4-1106: 128k tokens\n",
    "- gpt-3.5-turbo: 4k tokens\n",
    "- gpt-3.5-turbo-16k: 16k tokens\n",
    "- llama2: 4k tokens\n",
    "- mistral-7b: 8k tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b0f965",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef653473",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Not providing any examples via the prompt and simply using its built-in knowledge for solving the problem\n",
    "- Good way to see baseline performance on a problem, and where you may need to provide further examples or guidance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272177f4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In-Context Learning (Few-shot Prompting)\n",
    "- large language models have been shown to actually be able to 'learn' from examples\n",
    "- in-context learning refers to including examples in the prompt to teach the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b5e57b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Basic Starting Structure (Chat Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6efcb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Priming\n",
    "- Priming is where you tell the model what you want it to be, how to act, the role it should play\n",
    "- Examples: \"You are an expert _____\", \"You are a world leading ______\"\n",
    "- Priming helps activate the correct 'neurons' in the model and can help drastically change the quality of responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e043e46e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```\n",
    "<priming information>\n",
    "\n",
    "## Task\n",
    "\n",
    "<task description>\n",
    "\n",
    "## Format\n",
    "\n",
    "<format description>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a30fa2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why start so simple?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c8d4df",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- you want to see baseline, out-of-the box performance\n",
    "- you want to guage how much the language model understands your problem and domain\n",
    "- you want to incrementally iterate on your prompt and not actually make performance worse with unnecessary words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c44dc59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experiments to Assess In-Context Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d969273",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Completion Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a748786",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I feel you, just gotta push through and tomorrow will be a fresh start\n"
     ]
    }
   ],
   "source": [
    "# no in-context learning\n",
    "prompt = \"\"\"\n",
    "Tweet: Wish today was over\n",
    "\"\"\" \n",
    "print(completion(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42632e9b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "# using in-context learning\n",
    "prompt = \"\"\"\n",
    "Tweet: Decided to play with the new arduino for the first time - sooo easy to get started Now having fun with code and flashy lights!\t\n",
    "Sentiment: Positive\n",
    "\n",
    "Tweet: Hoping I at least have fun 2nite. Today was 1 horrible way 2 start off a birthday\n",
    "Sentiment: Negative\n",
    "\n",
    "Tweet: my poor puppy is a litle depress\t\n",
    "Sentiment: Negative\n",
    "\n",
    "Tweet: Goodnight and sweet dreams to you also\n",
    "Sentiment: Positive\n",
    "\n",
    "Tweet: Wish today was over\n",
    "\"\"\" \n",
    "print(completion(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743fcaa2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adfdb737",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "# no in-context learning\n",
    "prompt = \"You will be handed a tweet, classify the tweet as 'Positive' or 'Negative'\"\n",
    "message = \"Wish today was over\"\n",
    "\n",
    "print(chat_completion(message, prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d34ba9ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banana\n"
     ]
    }
   ],
   "source": [
    "# using in-context learning\n",
    "prompt = \"\"\"\n",
    "You are a helpful labeling assistant.\n",
    "\n",
    "## Task\n",
    "\n",
    "You will provided text, your job is to label the text as either 'Banana' or 'Boat'\n",
    "\n",
    "## Format\n",
    "\n",
    "Output only the label.\n",
    "\n",
    "## Examples\n",
    "\n",
    "Text: Decided to play with the new arduino for the first time - sooo easy to get started Now having fun with code and flashy lights!\t\n",
    "Label: Banana\n",
    "\n",
    "Text: Hoping I at least have fun 2nite. Today was 1 horrible way 2 start off a birthday\n",
    "Label: Boat\n",
    "\n",
    "Text: my poor puppy is a litle depress\t\n",
    "Label: Boat\n",
    "\n",
    "Text: Goodnight and sweet dreams to you also\n",
    "Label: Banana\n",
    "\"\"\"\n",
    "message = \"Today was a great day\"\n",
    "print(chat_completion(message, prompt=prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37226e72",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Response Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32bfc982",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# JSON response format\n",
    "prompt = \"\"\"\n",
    "You are a CSS and design expert.\n",
    "\n",
    "## Task\n",
    "\n",
    "You will be provided with a description of a mood, and your task is to generate the CSS code for a color that matches it.\n",
    "\n",
    "## Format\n",
    "\n",
    "Write your output in syntactically valid JSON with a single key called \"css_code\".\n",
    "\"\"\"\n",
    "message = \"happy\"\n",
    "color_json = chat_completion(message, prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e762d588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "background-color: #FFD700;\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "color_dict = json.loads(color_json)\n",
    "\n",
    "print(color_dict['css_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea20d324",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dynamic Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58c1fb0b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Jarvis. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\" \n",
    "You are a helpful AI assistant named {name}\n",
    "\"\"\".format(name=\"Jarvis\")\n",
    "\n",
    "message = \"What is your name?\"\n",
    "print(chat_completion(message, prompt=prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91f0dac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Self-Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244768f6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You want to design an AI solution that can take a user's questions and query a database to provide an answer.\n",
    "\n",
    "A classmate is doing this for their senior design project.\n",
    "\n",
    "Here is the prompt they are using:\n",
    "    \n",
    "```\n",
    "Convert the user's natural language question to SQL\n",
    "```\n",
    "\n",
    "Explain why this is less than ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc3edc2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Self-Check Answers\n",
    "- No priming of the model\n",
    "- No context (what database? what's the schema? what dialect of SQL?)\n",
    "- No formatting constraints\n",
    "- No examples (in-context learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "101ba948",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT AVG(total_order_value) \n",
      "FROM orders \n",
      "WHERE order_date = '2023-04-01'\n"
     ]
    }
   ],
   "source": [
    "def question_to_query_bad(question):\n",
    "    # bad\n",
    "    prompt = \"\"\"\n",
    "    Convert the user's natural language question to SQL\n",
    "    \"\"\"\n",
    "    \n",
    "    query = chat_completion(question, prompt=prompt)\n",
    "    \n",
    "    return query\n",
    "\n",
    "\n",
    "question = \"average total order value for all orders on 2023-04-01\"\n",
    "print(question_to_query_bad(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8ed8c8d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT AVG(total_order_value) \n",
      "FROM (\n",
      "    SELECT SUM(od.Quantity * p.UnitPrice) AS total_order_value\n",
      "    FROM Orders o\n",
      "    JOIN OrderDetails od ON o.OrderID = od.OrderID\n",
      "    JOIN Products p ON od.ProductID = p.ProductID\n",
      "    WHERE o.OrderDate = '2023-04-01'\n",
      "    GROUP BY o.OrderID\n",
      ") AS subquery;\n"
     ]
    }
   ],
   "source": [
    "def question_to_query_better(question):\n",
    "    # better\n",
    "    prompt = \"\"\"\n",
    "    You are an expert data analyst and SQL expert.\n",
    "\n",
    "    ## Task\n",
    "\n",
    "    Your job is to convert the user's natural language question's into syntactically valid PostgreSQL.\n",
    "\n",
    "    ## Schema\n",
    "\n",
    "    Use the following database schema:\n",
    "\n",
    "    ```\n",
    "    CREATE TABLE Orders (\n",
    "      OrderID int,\n",
    "      CustomerID int,\n",
    "      OrderDate datetime,\n",
    "      OrderTime varchar(8),\n",
    "      PRIMARY KEY (OrderID)\n",
    "    );\n",
    "\n",
    "    CREATE TABLE OrderDetails (\n",
    "      OrderDetailID int,\n",
    "      OrderID int,\n",
    "      ProductID int,\n",
    "      Quantity int,\n",
    "      PRIMARY KEY (OrderDetailID)\n",
    "    );\n",
    "\n",
    "    CREATE TABLE Products (\n",
    "      ProductID int,\n",
    "      ProductName varchar(50),\n",
    "      Category varchar(50),\n",
    "      UnitPrice decimal(10, 2),\n",
    "      Stock int,\n",
    "      PRIMARY KEY (ProductID)\n",
    "    );\n",
    "\n",
    "    CREATE TABLE Customers (\n",
    "      CustomerID int,\n",
    "      FirstName varchar(50),\n",
    "      LastName varchar(50),\n",
    "      Email varchar(100),\n",
    "      Phone varchar(20),\n",
    "      PRIMARY KEY (CustomerID)\n",
    "    );\n",
    "    ```\n",
    "\n",
    "    ## Format\n",
    "\n",
    "    Reply with only the SQL statement to answer the question.\n",
    "    \"\"\"\n",
    "    \n",
    "    query = chat_completion(question, prompt=prompt)\n",
    "\n",
    "    return query\n",
    "\n",
    "question = \"average total order value for all orders on 2023-04-01.\"\n",
    "print(question_to_query_better(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e32f67",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Chain-of-Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5a9560ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step-by-step Thought Process:\n",
      "- We need to calculate the average total order value for all orders on a specific date, which is 2023-04-01.\n",
      "- To calculate the total order value, we need to sum the unit prices of all products in each order and multiply it by the quantity.\n",
      "- Then, we need to calculate the average of these total order values.\n",
      "\n",
      "Query:\n",
      "```sql\n",
      "SELECT AVG(total_order_value) AS average_order_value\n",
      "FROM (\n",
      "  SELECT SUM(p.UnitPrice * od.Quantity) AS total_order_value\n",
      "  FROM Orders o\n",
      "  JOIN OrderDetails od ON o.OrderID = od.OrderID\n",
      "  JOIN Products p ON od.ProductID = p.ProductID\n",
      "  WHERE o.OrderDate = '2023-04-01'\n",
      "  GROUP BY o.OrderID\n",
      ") AS subquery;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "def question_to_query_cot(question):\n",
    "    prompt = \"\"\"\n",
    "    You are an expert data analyst and SQL expert.\n",
    "\n",
    "    ## Task\n",
    "\n",
    "    Your job is to convert the user's natural language question's into syntactically valid PostgreSQL.\n",
    "\n",
    "    ## Schema\n",
    "\n",
    "    Use the following database schema:\n",
    "\n",
    "    ```\n",
    "    CREATE TABLE Orders (\n",
    "      OrderID int,\n",
    "      CustomerID int,\n",
    "      OrderDate datetime,\n",
    "      OrderTime varchar(8),\n",
    "      PRIMARY KEY (OrderID)\n",
    "    );\n",
    "\n",
    "    CREATE TABLE OrderDetails (\n",
    "      OrderDetailID int,\n",
    "      OrderID int,\n",
    "      ProductID int,\n",
    "      Quantity int,\n",
    "      PRIMARY KEY (OrderDetailID)\n",
    "    );\n",
    "\n",
    "    CREATE TABLE Products (\n",
    "      ProductID int,\n",
    "      ProductName varchar(50),\n",
    "      Category varchar(50),\n",
    "      UnitPrice decimal(10, 2),\n",
    "      Stock int,\n",
    "      PRIMARY KEY (ProductID)\n",
    "    );\n",
    "\n",
    "    CREATE TABLE Customers (\n",
    "      CustomerID int,\n",
    "      FirstName varchar(50),\n",
    "      LastName varchar(50),\n",
    "      Email varchar(100),\n",
    "      Phone varchar(20),\n",
    "      PRIMARY KEY (CustomerID)\n",
    "    );\n",
    "    ```\n",
    "\n",
    "    ## Step-by-step Thought Process\n",
    "\n",
    "    In your step-by-step thought process, use as much space as you need. Think critically about the question, schema, and context.\n",
    "\n",
    "    ## Output Format\n",
    "\n",
    "    Step-by-step Thought Process: <let's think step-by-step>\n",
    "    Query: <the SQL query to run to answer the question>\n",
    "    \"\"\"\n",
    "\n",
    "    response = chat_completion(question, prompt=prompt)\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "question = \"average total order value for all orders on 2023-04-01.\"\n",
    "print(question_to_query_cot(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5694a09a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Formatting Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30a29cd3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def sql_formatter(text):\n",
    "    prompt = \"\"\"\n",
    "    You are an expert JSON formatter.\n",
    "    \n",
    "    ## Task\n",
    "    \n",
    "    You will be handed a blob of text with two sections:\n",
    "    \n",
    "    - Step-by-step Thought Process (or something similar)\n",
    "    - Query (or something similar)\n",
    "    \n",
    "    Your job is to convert this into syntactically valid JSON format.\n",
    "    \n",
    "    ## Format\n",
    "    \n",
    "    ```\n",
    "    {\n",
    "        \"step_by_step_thoughts\": \"<single string representing the full step-by-step thoughts>\",\n",
    "        \"sql\": \"<final sql query to execute>\"\n",
    "    }\n",
    "    ```\n",
    "    \n",
    "    Do not output the backticks, just the JSON.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = chat_completion(text, prompt=prompt)\n",
    "    data = json.loads(response)\n",
    "    \n",
    "    step_by_step_thoughts = data[\"step_by_step_thoughts\"]\n",
    "    sql = data[\"sql\"]\n",
    "    \n",
    "    return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b192de57",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT AVG(total_order_value) AS average_order_value\n",
      "FROM (\n",
      "  SELECT SUM(p.UnitPrice * od.Quantity) AS total_order_value\n",
      "  FROM Orders o\n",
      "  JOIN OrderDetails od ON o.OrderID = od.OrderID\n",
      "  JOIN Products p ON od.ProductID = p.ProductID\n",
      "  WHERE o.OrderDate = '2023-04-01'\n",
      "  GROUP BY o.OrderID\n",
      ") AS subquery;\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Step-by-step Thought Process:\n",
    "- We need to calculate the average total order value for all orders on a specific date, which is 2023-04-01.\n",
    "- To calculate the total order value, we need to sum the unit prices of all products in each order and multiply it by the quantity.\n",
    "- Then, we need to calculate the average of these total order values.\n",
    "\n",
    "Query:\n",
    "```sql\n",
    "SELECT AVG(total_order_value) AS average_order_value\n",
    "FROM (\n",
    "  SELECT SUM(p.UnitPrice * od.Quantity) AS total_order_value\n",
    "  FROM Orders o\n",
    "  JOIN OrderDetails od ON o.OrderID = od.OrderID\n",
    "  JOIN Products p ON od.ProductID = p.ProductID\n",
    "  WHERE o.OrderDate = '2023-04-01'\n",
    "  GROUP BY o.OrderID\n",
    ") AS subquery;\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "print(sql_formatter(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e62ea8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decomposition / Chaining Prompts Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ba8c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Just like in coding, we may want to _refactor_ our prompts to make them focused on a single responsibility\n",
    "- We can chain the output of one prompt and make it the input to another to decompose the problem into multiple steps\n",
    "- Easier to test / debug\n",
    "- Makes prompts more concise which can lead to many benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "17d629b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT AVG(total_order_value) AS average_order_value\n",
      "FROM (\n",
      "  SELECT SUM(p.UnitPrice * od.Quantity) AS total_order_value\n",
      "  FROM Orders o\n",
      "  JOIN OrderDetails od ON o.OrderID = od.OrderID\n",
      "  JOIN Products p ON od.ProductID = p.ProductID\n",
      "  WHERE o.OrderDate = '2023-04-01'\n",
      "  GROUP BY o.OrderID\n",
      ") AS subquery;\n"
     ]
    }
   ],
   "source": [
    "def natural_language_2_sql_chain(question):\n",
    "    thoughts = question_to_query(question)\n",
    "    query = sql_formatter(thoughts)\n",
    "    \n",
    "    return query\n",
    "\n",
    "question = \"average total order value for all orders on 2023-04-01.\"\n",
    "print(natural_language_2_sql_chain(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f06be",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review\n",
    "- Priming\n",
    "- Using Markdown\n",
    "- Zero-Shot / Few-Shot Prompting\n",
    "- Asking for specific formats\n",
    "- Using `.format` to use variables in prompts\n",
    "- Providing context\n",
    "- Chain-of-Thought Prompting\n",
    "- Formatters\n",
    "- Decomposition / Refactoring / Chaining prompts together"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
