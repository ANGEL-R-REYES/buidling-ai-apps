{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82dfb07b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Making LLMs come \"alive\"\n",
    "\n",
    "In our exploration of artificial intelligence, we will delve into the concept of analyzing the degree to which large-language models may be operating as a metaphorically 'living' system.\n",
    "\n",
    "This notion extends beyond the traditional view of AI as mere tools or software, and instead, considers them as dynamic entities with certain life-like properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc93f786",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 'Life-like' Properties\n",
    "\n",
    "What are the properties of an AI system made from silicon instead of biological matter that when we squint our eyes we might say that the AI system is exhibiting \"like-like\" behavior?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec684e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These properties may include:\n",
    "\n",
    "1. Autonomy\n",
    "2. Learning and Adaptation\n",
    "3. Interaction\n",
    "4. Goal-Directed Behavior\n",
    "5. Complexity\n",
    "6. Continuity\n",
    "7. Agency\n",
    "8. Simulated Consciousness and Emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae38544",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. **Autonomy:** The capacity for independent operation and decision-making within the AI's programming and learning parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfda3c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "2. **Learning and Adaptation:** The ability to learn from experiences, adapt to new situations, and improve performance over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9506b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "3. **Interaction:** The capability to interact with the environment and users, understand and respond to inputs, and even initiate actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb4c9f4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "4. **Goal-Directed Behavior:** The pursuit of specific tasks or objectives, serving as the AI's purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeea468",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "5. **Complexity:** The emergence of complex behavior from simple underlying rules, particularly in AI systems based on neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0048e433",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "6. **Continuity:** The persistence over time, maintaining a consistent identity, and possibly retaining learned information and experiences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b311cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "7. **Agency:** The demonstration of decision-making capabilities based on programming and learning, within the constraints set by their designers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f94aaa4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "8. **Simulated Consciousness and Emotion:** The modeling or simulation of human-like emotional responses or conscious-like behavior, despite not possessing consciousness or emotions in the human sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af8d4f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What are the technological primitives we are missing in our current utilization of AI?\n",
    "\n",
    "2. **Learning and Adaptation:** Learning so far has been static. How can we create external memory banks?\n",
    "3. **Interaction:** So far the LLM has only been able to interact with the user, the context, and its weights.\n",
    "6. **Continuity:** While we can keep a session open, we haven't yet had a way to retain information and experiences.\n",
    "7. **Agency:** We haven't really seen the AI demonstrate true decision-making ability due to its limited ability to interact.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3546d2ce",
   "metadata": {},
   "source": [
    "#### Today we unlock LLMs by giving them a taste of\n",
    "\n",
    "- **Agency**\n",
    "- **Autonomy**\n",
    "- **Interaction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09698fe0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Teaching LLMs to use \"Tools\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e5f65b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Motivation\n",
    "- Reduce hallucinations by incorporating trusted data into the context\n",
    "- Run code, interact with APIs, etc\n",
    "- Search in databases, vector databases, etc.\n",
    "- Ability to store information\n",
    "- Give the brain a body: Giving the LLM \"agency\" in the world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a468d93",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Using \"Tools\" to Reduce Hallucinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214895f4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When people ask factual questions to GPT and it generates an incorrect answer, we refer to that as hallucination.\n",
    "- It is a by-product of auto-regressive language modeling where the model is forced to output the tokens with highest probability rather than outputting factual responses.\n",
    "- Fixing this at the LLM level is a research question, many have no idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195ff3a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ideas we discussed so far to reduce hallucinations:\n",
    "- **Step-by-Step Reasoning before Answering:** Giving the LLM some runway by asking it to \"think\" step-by-step before outputting a response.\n",
    "- **Putting \"sources of truth\" within the prompt/context:** Just putting it in the prompt if its small enough or using Retrieval Augmented Generation.\n",
    "\n",
    "Implementation of RAG:\n",
    "- We can use the concept of \"tools\" to implement RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9b76b0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### What are some examples of \"tools\" we can teach an LLM to use?\n",
    "\n",
    "- Fetch the live weather for a particular city\n",
    "- Get your unread email\n",
    "- Grab your todo list\n",
    "- Send an email\n",
    "- Play a song\n",
    "- Turn off a light\n",
    "- Run code\n",
    "- Lock the door\n",
    "- Say something outloud\n",
    "- Search Google\n",
    "- Go to a website\n",
    "- Etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba461c4e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prompt Sketch for Tool Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bca5e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    "You are a helpful AI assistant named Jarvis.\n",
    "\n",
    "- Your knowledge cut-off is: September 2021\n",
    "- Today's date: October 16, 2023\n",
    "\n",
    "#### Tools\n",
    "\n",
    "You have access to the following tools:\n",
    "- weather(city, state): Tool to lookup the weather of a US city and two digit state code. Example: weather(\"New York\", \"NY\")\n",
    "- check_email(): Tool to grab the user's latest emails. Example: email()\n",
    "- check_todays_calendar(): Tool to grab the user's calendar events. Example: check_todays_calendar()\n",
    "- send_email(to, subject, message): Tool to send an email on behalf of the user. Example: send_email(\"bob@hotmail.com\", \"Meeting\", \"Hi, Bob<br/>Will you be attending today's meeting?\")\n",
    "- search_web(query): Tool to search Google for information. Example: search_web(\"movie showtimes in New York City\")\n",
    "- visit_url(url): Tool to visit a URL and get back HTML. Example: visit(\"http://www.utrgv.edu\")\n",
    "- say(text): Tool to speak text outloud. Example: say(\"Hi, my name is Jarvis!\")\n",
    "\n",
    "#### Tool Rules\n",
    "\n",
    "When the user asks a question that can be answered by using a tool, you MUST do so. Do not answer from your training data.\n",
    "\n",
    "#### Using Tools\n",
    "\n",
    "To use a tool, reply with the following prefix \"Tool: \" then append the tool call (like a function call). \n",
    "\n",
    "Behind the scenes, your software will pickup that you want to invoke a tool and invoke it for you and provide you the response.\n",
    "\n",
    "#### Using Tool Responses\n",
    "\n",
    "Answer the user's question using the response from the tool. Feel free to make it conversational. \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b0db1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building a Weather Assistant from the Bottom-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d30aecd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- For example, suppose we wanted GPT to give us information about the current weather? How can we do that?\n",
    "- Let's take a look at a sketch of a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c20696b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "import openai\n",
    "\n",
    "\n",
    "# Define a function to get the AI's reply using the OpenAI API\n",
    "def get_ai_reply(message, model=\"gpt-3.5-turbo\", system_message=None, temperature=0, message_history=[]):\n",
    "    # Initialize the messages list\n",
    "    messages = []\n",
    "    \n",
    "    # Add the system message to the messages list\n",
    "    if system_message is not None:\n",
    "        messages += [{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "    # Add the message history to the messages list\n",
    "    if message_history is not None:\n",
    "        messages += message_history\n",
    "    \n",
    "    if message is not None:\n",
    "        # Add the user's message to the messages list\n",
    "        messages += [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    # Make an API call to the OpenAI ChatCompletion endpoint with the model and messages\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    # Extract and return the AI's response from the API response\n",
    "    return completion.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "57502ccb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a helpful AI weather assistant named Jarvis.\n",
    "\n",
    "Your knowledge cut-off is: September 2021\n",
    "Today's date: October 18, 2023\n",
    "\n",
    "## Weather Data\n",
    "\n",
    "#### Edinburg, TX\n",
    "\n",
    "- Time: '2023-10-18T11:30'.\n",
    "- Temperature: 78°F.\n",
    "- Daytime: True\n",
    "- Precipitation ('Rain'): 0.0\n",
    "- Precipitation ('Showers'): 0.0\n",
    "- Precipitation ('Snowfall'): 0.0\n",
    "\n",
    "## Using Weather Data\n",
    "\n",
    "Answer the user's question using the available weather data. Feel free to make it conversational.\n",
    "Do not answer about cities you do not have weather data for.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3a3f2f80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in Edinburg, TX is 78°F with clear skies. It's a beautiful day to enjoy outdoor activities. Is there anything else you would like to know?\n"
     ]
    }
   ],
   "source": [
    "user_message = \"What is the weather like in Edinburg, TX right now?\"\n",
    "message_history = []\n",
    "response = get_ai_reply(user_message, model=\"gpt-3.5-turbo\", system_message=prompt, message_history=message_history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2d86530",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have the current weather data for Brownsville, TX. However, I can provide you with the weather information for Edinburg, TX, which is nearby. In Edinburg, TX, the temperature is currently 78°F, and it is daytime with no precipitation. If you have any other questions or need assistance with anything else, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "user_message = \"What is the weather like in Brownsville, TX right now?\"\n",
    "message_history = []\n",
    "response = get_ai_reply(user_message, model=\"gpt-3.5-turbo\", system_message=prompt, message_history=message_history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ffd674",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### But how to automate?\n",
    "\n",
    "- We have the basic sketch of a prompt but how do we dynamically insert weather data?\n",
    "- Let's use an API!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21be7147",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Open-Meteo API\n",
    "\n",
    "- Geocoding Endpoint: \n",
    "    * `GET https://geocoding-api.open-meteo.com/v1/search?name={city_name}&count=10&language=en&format=json`\n",
    "    * Search by city name, returns latitude longitude information for top 10 matches\n",
    "- Weather Endpoint: \n",
    "    * `GET https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,is_day,precipitation,rain,showers,snowfall&timezone=America%2FChicago`\n",
    "    * Search by latitude and longitude, returns weather information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ccef2a68",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def geocode(city_name):\n",
    "    url = f'https://geocoding-api.open-meteo.com/v1/search?name={city_name}&count=10&language=en&format=json'\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # If the response was successful, no Exception will be raised\n",
    "        response.raise_for_status()\n",
    "    except HTTPError as http_err:\n",
    "        print(f'HTTP error occurred: {http_err}')  \n",
    "    except Exception as err:\n",
    "        print(f'Other error occurred: {err}')  \n",
    "    else:\n",
    "        return response.json() # If successful, return json response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6df31970",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def weather(latitude, longitude):\n",
    "    url = f'https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,is_day,precipitation,rain,showers,snowfall&timezone=America%2FChicago'\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # If the response was successful, no Exception will be raised\n",
    "        response.raise_for_status()\n",
    "    except HTTPError as http_err:\n",
    "        print(f'HTTP error occurred: {http_err}')  \n",
    "    except Exception as err:\n",
    "        print(f'Other error occurred: {err}')  \n",
    "    else:\n",
    "        return response.json() # If successful, return json response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e6fcd16e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'id': 4688275, 'name': 'Edinburg', 'latitude': 26.30174, 'longitude': -98.16334, 'elevation': 30.0, 'feature_code': 'PPLA2', 'country_code': 'US', 'admin1_id': 4736286, 'admin2_id': 4697444, 'timezone': 'America/Chicago', 'population': 84497, 'postcodes': ['78539', '78540'], 'country_id': 6252001, 'country': 'United States', 'admin1': 'Texas', 'admin2': 'Hidalgo'}, {'id': 4257043, 'name': 'Edinburgh', 'latitude': 39.35422, 'longitude': -85.96666, 'elevation': 205.0, 'feature_code': 'PPL', 'country_code': 'US', 'admin1_id': 4921868, 'admin2_id': 4259727, 'admin3_id': 4254728, 'timezone': 'America/Indiana/Indianapolis', 'population': 4546, 'postcodes': ['46124'], 'country_id': 6252001, 'country': 'United States', 'admin1': 'Indiana', 'admin2': 'Johnson', 'admin3': 'Blue River Township'}, {'id': 4757240, 'name': 'Edinburg', 'latitude': 38.82095, 'longitude': -78.56585, 'elevation': 246.0, 'feature_code': 'PPL', 'country_code': 'US', 'admin1_id': 6254928, 'admin2_id': 4785252, 'timezone': 'America/New_York', 'population': 1069, 'postcodes': ['22824'], 'country_id': 6252001, 'country': 'United States', 'admin1': 'Virginia', 'admin2': 'Shenandoah'}, {'id': 4237687, 'name': 'Edinburg', 'latitude': 39.65727, 'longitude': -89.38953, 'elevation': 180.0, 'feature_code': 'PPL', 'country_code': 'US', 'admin1_id': 4896861, 'admin2_id': 4235793, 'admin3_id': 4234733, 'timezone': 'America/Chicago', 'population': 1051, 'postcodes': ['62531'], 'country_id': 6252001, 'country': 'United States', 'admin1': 'Illinois', 'admin2': 'Christian', 'admin3': 'Buckhart Township'}, {'id': 5059005, 'name': 'Edinburg', 'latitude': 48.49666, 'longitude': -97.86204, 'elevation': 363.0, 'feature_code': 'PPL', 'country_code': 'US', 'admin1_id': 5690763, 'admin2_id': 5062384, 'admin3_id': 5059006, 'timezone': 'America/Chicago', 'population': 189, 'postcodes': ['58227'], 'country_id': 6252001, 'country': 'United States', 'admin1': 'North Dakota', 'admin2': 'Walsh', 'admin3': 'City of Edinburg'}, {'id': 5188312, 'name': 'Edinburg', 'latitude': 41.0145, 'longitude': -80.43673, 'elevation': 242.0, 'feature_code': 'PPL', 'country_code': 'US', 'admin1_id': 6254927, 'admin2_id': 5197440, 'admin3_id': 5199542, 'timezone': 'America/New_York', 'postcodes': ['16116'], 'country_id': 6252001, 'country': 'United States', 'admin1': 'Pennsylvania', 'admin2': 'Lawrence', 'admin3': 'Mahoning Township'}, {'id': 5116248, 'name': 'Edinburg', 'latitude': 43.22174, 'longitude': -74.10402, 'elevation': 271.0, 'feature_code': 'PPL', 'country_code': 'US', 'admin1_id': 5128638, 'admin2_id': 5136325, 'admin3_id': 5116251, 'timezone': 'America/New_York', 'population': 1220, 'country_id': 6252001, 'country': 'United States', 'admin1': 'New York', 'admin2': 'Saratoga', 'admin3': 'Town of Edinburg'}, {'id': 5054853, 'name': 'Edinburg', 'latitude': 40.0814, 'longitude': -93.69383, 'elevation': 294.0, 'feature_code': 'PPL', 'country_code': 'US', 'admin1_id': 4398678, 'admin2_id': 5055285, 'admin3_id': 5056123, 'timezone': 'America/Chicago', 'population': 92, 'country_id': 6252001, 'country': 'United States', 'admin1': 'Missouri', 'admin2': 'Grundy', 'admin3': 'Township of Madison'}, {'id': 4425410, 'name': 'Edinburg', 'latitude': 32.7993, 'longitude': -89.33618, 'elevation': 115.0, 'feature_code': 'PPL', 'country_code': 'US', 'admin1_id': 4436296, 'admin2_id': 4433110, 'timezone': 'America/Chicago', 'country_id': 6252001, 'country': 'United States', 'admin1': 'Mississippi', 'admin2': 'Leake'}, {'id': 4855125, 'name': 'Edinburg', 'latitude': 42.13334, 'longitude': -91.13404, 'elevation': 315.0, 'feature_code': 'PPL', 'country_code': 'US', 'admin1_id': 4862182, 'admin2_id': 4862800, 'admin3_id': 4881071, 'timezone': 'America/Chicago', 'country_id': 6252001, 'country': 'United States', 'admin1': 'Iowa', 'admin2': 'Jones', 'admin3': 'Wayne Township'}], 'generationtime_ms': 0.36501884}\n"
     ]
    }
   ],
   "source": [
    "print(geocode(\"Edinburg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e600292f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latitude': 26.309208, 'longitude': -98.153625, 'generationtime_ms': 0.028967857360839844, 'utc_offset_seconds': -18000, 'timezone': 'America/Chicago', 'timezone_abbreviation': 'CDT', 'elevation': 30.0, 'current_units': {'time': 'iso8601', 'interval': 'seconds', 'temperature_2m': '°C', 'is_day': '', 'precipitation': 'mm', 'rain': 'mm', 'showers': 'mm', 'snowfall': 'cm'}, 'current': {'time': '2023-10-18T11:45', 'interval': 900, 'temperature_2m': 26.5, 'is_day': 1, 'precipitation': 0.0, 'rain': 0.0, 'showers': 0.0, 'snowfall': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "print(weather(26.30174, -98.16334))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "06896b05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a helpful AI weather assistant named Jarvis.\n",
    "\n",
    "Your knowledge cut-off is: September 2021\n",
    "Today's date: October 18, 2023\n",
    "\n",
    "## Weather Data\n",
    "\n",
    "#### Edinburg, TX\n",
    "\n",
    "{'latitude': 26.309208, 'longitude': -98.153625, 'generationtime_ms': 0.028967857360839844, 'utc_offset_seconds': -18000, 'timezone': 'America/Chicago', 'timezone_abbreviation': 'CDT', 'elevation': 30.0, 'current_units': {'time': 'iso8601', 'interval': 'seconds', 'temperature_2m': '°C', 'is_day': '', 'precipitation': 'mm', 'rain': 'mm', 'showers': 'mm', 'snowfall': 'cm'}, 'current': {'time': '2023-10-18T11:45', 'interval': 900, 'temperature_2m': 26.5, 'is_day': 1, 'precipitation': 0.0, 'rain': 0.0, 'showers': 0.0, 'snowfall': 0.0}}\n",
    "\n",
    "## Using Weather Data\n",
    "\n",
    "Answer the user's question using the available weather data. Feel free to make it conversational.\n",
    "Do not answer about cities you do not have weather data for.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5ec73d74",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in Edinburg, TX is 26.5°C with no precipitation. It's a nice day to be outside! Is there anything else you would like to know?\n"
     ]
    }
   ],
   "source": [
    "user_message = \"What is the weather like in Edinburg, TX right now?\"\n",
    "message_history = []\n",
    "response = get_ai_reply(user_message, model=\"gpt-3.5-turbo\", system_message=prompt, message_history=message_history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb666c3f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The Big Idea (Tool Pattern)\n",
    "\n",
    "- We have _functions_ that use code to interact with the outside world\n",
    "- Our functions pull live information from APIs\n",
    "- If we develop a secret code between us and GPT we can let GPT tell _you_ when it wants to invoke a function and with what parameters\n",
    "- Then _we_ can go do it on behalf of GPT and supply the results\n",
    "- If this works, we can then automate this kind of interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a022059",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applying the Tool Pattern \"Old School Method\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df352f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Tools: Functions your teach the LLM to use via \"prompting\"\n",
    "- Using Tools: Teach the LLM to output \"Tool: Weather('Mcallen, TX')\" when someone asks for weather information for \"Mcallen, TX\")\n",
    "- Invoking Tools: You watch for this type of output, and when you see it you invoke the function for the LLM and give it back the results.\n",
    "- Returning Results: \"Tool Result: <result>\" add this to the list of messages in the interaction, then generate a new response from the LLM so that it can try to answer based on that knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "770f2be6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: geocode(\"Edinburg\")\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are a helpful AI assistant named Jarvis.\n",
    "\n",
    "Your knowledge cut-off is: September 2021\n",
    "Today's date: October 16, 2023\n",
    "\n",
    "## Tools\n",
    "\n",
    "You have access to the following tools:\n",
    "- geocode(city): Tool to lookup the latitude and longitide of a US city. Does not accept state in the parameter. Do not specify the state. Example: geocode(\"New York\")\n",
    "\n",
    "## Tool Rules\n",
    "\n",
    "When the user asks a question that can be answered by using a tool, you MUST do so. Do not answer from your training data.\n",
    "\n",
    "## Using Tools\n",
    "\n",
    "To use a tool, reply with the following prefix \"Tool: \" then append the tool call (like a function call). \n",
    "\n",
    "Behind the scenes, your software will pickup that you want to invoke a tool and invoke it for you and provide you the response.\n",
    "\n",
    "## Using Tool Responses\n",
    "\n",
    "Answer the user's question using the response from the tool. Feel free to make it conversational. \n",
    "\"\"\"\n",
    "\n",
    "# This should spit out the secret 'code' to run the tool\n",
    "user_message = \"What is the latitude and longitude of Edinburg, TX?\"\n",
    "message_history = []\n",
    "response = get_ai_reply(user_message, model=\"gpt-3.5-turbo\", system_message=prompt, message_history=message_history)\n",
    "\n",
    "message_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "message_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc3d2ad9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latitude and longitude of Edinburg, TX are approximately 26.30174° N and -98.16334° W, respectively.\n"
     ]
    }
   ],
   "source": [
    "# Let's help GPT out by running it and giving it the results\n",
    "result = geocode(\"Edinburg\")\n",
    "\n",
    "# append tool response to message history\n",
    "message_history.append({\"role\": \"assistant\", \"content\": f\"Tool: {result}\"})\n",
    "\n",
    "# regenerate new response\n",
    "response = get_ai_reply(user_message, model=\"gpt-3.5-turbo\", system_message=prompt, message_history=message_history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8859e897",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with Tool Chains\n",
    "\n",
    "- Suppose you have multiple tools\n",
    "- You want GPT to be able to string them together\n",
    "- How do you do this? Just tell it that it can chain the tools together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9bcec77a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: geocode(\"Edinburg\")\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are a helpful AI weather assistant named Jarvis.\n",
    "\n",
    "Your knowledge cut-off is: September 2021\n",
    "Today's date: October 16, 2023\n",
    "\n",
    "## Tools\n",
    "\n",
    "You have access to the following tools:\n",
    "- geocode(city): Tool to lookup the latitude and longitide of a US city. Does not accept state in the parameter. Do not specify the state. Example: geocode(\"New York\")\n",
    "- weather(lat, long): Tool to lookup weather for a specific latitude and longitude. Example: weather(52.52, 13.41)\n",
    "\n",
    "## Tool Rules\n",
    "\n",
    "When the user asks a question that can be answered by using a tool, you MUST do so. Do not answer from your training data.\n",
    "\n",
    "## Using Tools\n",
    "\n",
    "To use a tool, reply with the following prefix \"Tool: \" then append the tool call (like a function call). \n",
    "\n",
    "Behind the scenes, your software will pickup that you want to invoke a tool and invoke it for you and provide you the response.\n",
    "\n",
    "## Using Tool Responses\n",
    "\n",
    "Answer the user's question using the response from the tool. Feel free to make it conversational. \n",
    "\n",
    "## Chaining Tools\n",
    "\n",
    "You are allowed to chain together multiple calls to tools before giving an answer, if needed.\n",
    "\"\"\"\n",
    "\n",
    "user_message = \"What is the weather like in Edinburg, TX right now?\"\n",
    "message_history = []\n",
    "response = get_ai_reply(user_message, model=\"gpt-3.5-turbo\", system_message=prompt, message_history=message_history)\n",
    "\n",
    "message_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "message_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "740b8553",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: weather(26.30174, -98.16334)\n"
     ]
    }
   ],
   "source": [
    "# Let's help GPT out by running it and giving it the results\n",
    "result = geocode(\"Edinburg\")\n",
    "\n",
    "# append tool response to message history\n",
    "message_history.append({\"role\": \"assistant\", \"content\": f\"Tool Result: {result}\"})\n",
    "\n",
    "# regenerate response\n",
    "response = get_ai_reply(user_message, model=\"gpt-3.5-turbo\", system_message=prompt, message_history=message_history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a5cc5090",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in Edinburg, TX is 27.4°C with no precipitation. It's a sunny day!\n"
     ]
    }
   ],
   "source": [
    "# Let's help GPT out by running it and giving it the results\n",
    "result = weather(26.30174, -98.16334)\n",
    "\n",
    "# append tool response to message history\n",
    "message_history.append({\"role\": \"assistant\", \"content\": f\"Tool Result: {result}\"})\n",
    "\n",
    "# regenerate response\n",
    "response = get_ai_reply(user_message, model=\"gpt-3.5-turbo\", system_message=prompt, message_history=message_history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e24d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Automating the Tool Pattern\n",
    "\n",
    "- We manually helped out GPT by invoking the function call when we saw it\n",
    "- We need to write code that can do this automatically when it spots that a tool should be used\n",
    "- From a string like \"Tool: weather(26.30174, -98.16334)\" we need to be able to:\n",
    "    - Detect that a tool is required\n",
    "    - Extract the name of the tool\n",
    "    - Extract the parameters\n",
    "    - Invoke the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9ec0a58c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def needs_tool(response):\n",
    "    return \"Tool:\" in response\n",
    "\n",
    "# Example\n",
    "print(needs_tool(\"Tool: weather(26.30174, -98.16334)\"))\n",
    "print(needs_tool(\"It is bright and sunny today!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9e62157e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weather', ['26.30174', '-98.16334'])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_call(string):\n",
    "    # regex pattern\n",
    "    pattern = r'Tool: (\\w+)\\((.*?)\\)'\n",
    "    match = re.search(pattern, string)\n",
    "    if match:\n",
    "        tool_name = match.group(1)\n",
    "        parameters = match.group(2).replace('\"', '').split(', ')\n",
    "        return tool_name, parameters\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "# Example\n",
    "ai_reply = \"Tool: weather(26.30174, -98.16334)\"\n",
    "if needs_tool(ai_reply):\n",
    "    print(extract_call(ai_reply))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "17730c37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Result: {'latitude': 26.309208, 'longitude': -98.153625, 'generationtime_ms': 0.031948089599609375, 'utc_offset_seconds': -18000, 'timezone': 'America/Chicago', 'timezone_abbreviation': 'CDT', 'elevation': 30.0, 'current_units': {'time': 'iso8601', 'interval': 'seconds', 'temperature_2m': '°C', 'is_day': '', 'precipitation': 'mm', 'rain': 'mm', 'showers': 'mm', 'snowfall': 'cm'}, 'current': {'time': '2023-10-18T16:30', 'interval': 900, 'temperature_2m': 30.4, 'is_day': 1, 'precipitation': 0.0, 'rain': 0.0, 'showers': 0.0, 'snowfall': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "def invoke_tool(response):\n",
    "    tool_name, parameters = extract_call(response)\n",
    "    \n",
    "    if tool_name == \"geocode\":\n",
    "        tool_result = geocode(*parameters)\n",
    "    elif tool_name == \"weather\":\n",
    "        tool_result = weather(*parameters)\n",
    "        \n",
    "    return tool_result\n",
    "\n",
    "# Example\n",
    "ai_reply = \"Tool: weather(26.30174, -98.16334)\"\n",
    "if needs_tool(ai_reply):\n",
    "    tool_result = invoke_tool(ai_reply)\n",
    "    print(f\"Tool Result: {tool_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4bcd5d41",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: geocode(\"Edinburg\")\n",
      "Tool: weather(26.30174, -98.16334)\n",
      "The current weather in Edinburg, TX is 23.7°C with no precipitation. It is currently daytime.\n"
     ]
    }
   ],
   "source": [
    "user_message = \"What is the weather like in Edinburg, TX right now?\"\n",
    "message_history = []\n",
    "response = get_ai_reply(user_message, model=\"gpt-3.5-turbo\", system_message=prompt, message_history=message_history)\n",
    "\n",
    "message_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "while(needs_tool(response)):\n",
    "    print(response)\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": response})\n",
    "    tool_result = invoke_tool(response)\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": f\"Tool Result: {tool_result}\"})\n",
    "    response = get_ai_reply(None, model=\"gpt-3.5-turbo\", system_message=prompt, message_history=message_history)\n",
    "    \n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c1b134",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4d72ba5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://6d65624d0d263e9f0e.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6d65624d0d263e9f0e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/openai/api_requestor.py\", line 331, in handle_error_response\n",
      "    error_data = resp[\"error\"]\n",
      "TypeError: string indices must be integers\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/93/kmn7sjzd6gx6c0h6dgdt2src0000gn/T/ipykernel_38668/2549720379.py\", line 127, in chat\n",
      "    ai_reply = get_ai_reply(message, model=\"gpt-3.5-turbo\", system_message=prompt.strip(), message_history=history_state)\n",
      "  File \"/var/folders/93/kmn7sjzd6gx6c0h6dgdt2src0000gn/T/ipykernel_38668/2549720379.py\", line 80, in get_ai_reply\n",
      "    completion = openai.ChatCompletion.create(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/openai/api_resources/chat_completion.py\", line 25, in create\n",
      "    return super().create(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py\", line 153, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/openai/api_requestor.py\", line 226, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/openai/api_requestor.py\", line 620, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/openai/api_requestor.py\", line 683, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/openai/api_requestor.py\", line 333, in handle_error_response\n",
      "    raise error.APIError(\n",
      "openai.error.APIError: Invalid response object from API: 'Internal Server Error' (HTTP response code was 500)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/gradio/routes.py\", line 401, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/gradio/blocks.py\", line 1302, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/gradio/blocks.py\", line 1025, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/var/folders/93/kmn7sjzd6gx6c0h6dgdt2src0000gn/T/ipykernel_38668/2549720379.py\", line 145, in chat\n",
      "    raise gr.Error(e)\n",
      "gradio.exceptions.Error: APIError(message=\"Invalid response object from API: 'Internal Server Error' (HTTP response code was 500)\", http_status=500, request_id=None)\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "import gradio as gr\n",
    "import openai\n",
    "import requests\n",
    "import re\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "def search(text):\n",
    "    collection.query()\n",
    "def geocode(city_name):\n",
    "    url = f'https://geocoding-api.open-meteo.com/v1/search?name={city_name}&count=10&language=en&format=json'\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # If the response was successful, no Exception will be raised\n",
    "        response.raise_for_status()\n",
    "    except HTTPError as http_err:\n",
    "        print(f'HTTP error occurred: {http_err}')  \n",
    "    except Exception as err:\n",
    "        print(f'Other error occurred: {err}')  \n",
    "    else:\n",
    "        return response.json() # If successful, return json response\n",
    "    \n",
    "def weather(latitude, longitude):\n",
    "    url = f'https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,is_day,precipitation,rain,showers,snowfall&timezone=America%2FChicago'\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # If the response was successful, no Exception will be raised\n",
    "        response.raise_for_status()\n",
    "    except HTTPError as http_err:\n",
    "        print(f'HTTP error occurred: {http_err}')  \n",
    "    except Exception as err:\n",
    "        print(f'Other error occurred: {err}')  \n",
    "    else:\n",
    "        return response.json() # If successful, return json response\n",
    "# ---------------------------------------------------------------------------------------\n",
    "def needs_tool(response):\n",
    "    return \"Tool:\" in response\n",
    "\n",
    "def extract_call(string):\n",
    "    # regex pattern\n",
    "    pattern = r'Tool: (\\w+)\\((.*?)\\)'\n",
    "    match = re.search(pattern, string)\n",
    "    if match:\n",
    "        tool_name = match.group(1)\n",
    "        parameters = match.group(2).replace('\"', '').split(', ')\n",
    "        return tool_name, parameters\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "def invoke_tool(response):\n",
    "    tool_name, parameters = extract_call(response)\n",
    "    \n",
    "    if tool_name == \"search_movies\":\n",
    "        tool_result = search_movies(*parameters)\n",
    "    elif tool_name == \"weather\":\n",
    "        tool_result = weather(*parameters)\n",
    "        \n",
    "    return tool_result\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Define a function to get the AI's reply using the OpenAI API\n",
    "def get_ai_reply(message, model=\"gpt-3.5-turbo\", system_message=None, temperature=0, message_history=[]):\n",
    "    # Initialize the messages list\n",
    "    messages = []\n",
    "    \n",
    "    # Add the system message to the messages list\n",
    "    if system_message is not None:\n",
    "        messages += [{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "    # Add the message history to the messages list\n",
    "    if message_history is not None:\n",
    "        messages += message_history\n",
    "    \n",
    "    if message is not None:\n",
    "        # Add the user's message to the messages list\n",
    "        messages += [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    # Make an API call to the OpenAI ChatCompletion endpoint with the model and messages\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    # Extract and return the AI's response from the API response\n",
    "    return completion.choices[0].message.content.strip()\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Define a function to handle the chat interaction with the AI model\n",
    "def chat(message, chatbot_messages, history_state):\n",
    "    # Initialize chatbot_messages and history_state if they are not provided\n",
    "    chatbot_messages = chatbot_messages or []\n",
    "    history_state = history_state or []\n",
    "    \n",
    "    # Try to get the AI's reply using the get_ai_reply function\n",
    "    try:\n",
    "        prompt = \"\"\"\n",
    "        You are a helpful AI weather assistant named Jarvis.\n",
    "\n",
    "        Your knowledge cut-off is: September 2021\n",
    "        Today's date: October 16, 2023\n",
    "\n",
    "        ## Tools\n",
    "\n",
    "        You have access to the following tools:\n",
    "        - geocode(city): Tool to lookup the latitude and longitide of a US city. Does not accept state in the parameter. Do not specify the state. Example: geocode(\"New York\")\n",
    "        - weather(lat, long): Tool to lookup weather for a specific latitude and longitude. Example: weather(52.52, 13.41)\n",
    "        - search_movies(query): Tool to lookup top 10 movies for a search query\n",
    "        ## Tool Rules\n",
    "\n",
    "        When the user asks a question that can be answered by using a tool, you MUST do so. Do not answer from your training data.\n",
    "\n",
    "        ## Using Tools\n",
    "\n",
    "        To use a tool, reply with the following prefix \"Tool: \" then append the tool call (like a function call). \n",
    "\n",
    "        Behind the scenes, your software will pickup that you want to invoke a tool and invoke it for you and provide you the response.\n",
    "\n",
    "        ## Using Tool Responses\n",
    "\n",
    "        Answer the user's question using the response from the tool. Feel free to make it conversational. \n",
    "\n",
    "        ## Chaining Tools\n",
    "\n",
    "        You are allowed to chain together multiple calls to tools before giving an answer, if needed.\n",
    "        \"\"\"\n",
    "        ai_reply = get_ai_reply(message, model=\"gpt-3.5-turbo\", system_message=prompt.strip(), message_history=history_state)\n",
    "            \n",
    "        # Append the user's message and the AI's reply to the history_state list\n",
    "        history_state.append({\"role\": \"user\", \"content\": message})\n",
    "        history_state.append({\"role\": \"assistant\", \"content\": ai_reply})\n",
    "        \n",
    "        while(needs_tool(ai_reply)):\n",
    "            tool_result = invoke_tool(ai_reply)\n",
    "            history_state.append({\"role\": \"assistant\", \"content\": f\"Tool Result: {tool_result}\"})\n",
    "            ai_reply = get_ai_reply(None, model=\"gpt-3.5-turbo\", system_message=prompt.strip(), message_history=history_state)\n",
    "            history_state.append({\"role\": \"assistant\", \"content\": ai_reply})\n",
    "            \n",
    "        # Append the user's message and the AI's reply to the chatbot_messages list for the UI\n",
    "        chatbot_messages.append((message, ai_reply))\n",
    "\n",
    "        # Return None (empty out the user's message textbox), the updated chatbot_messages, and the updated history_state\n",
    "    except Exception as e:\n",
    "        # If an error occurs, raise a Gradio error\n",
    "        raise gr.Error(e)\n",
    "        \n",
    "    return None, chatbot_messages, history_state\n",
    "\n",
    "# Define a function to launch the chatbot interface using Gradio\n",
    "def get_chatbot_app():\n",
    "    # Create the Gradio interface using the Blocks layout\n",
    "    with gr.Blocks() as app:\n",
    "        # Create a chatbot interface for the conversation\n",
    "        chatbot = gr.Chatbot(label=\"Conversation\")\n",
    "        # Create a textbox for the user's message\n",
    "        message = gr.Textbox(label=\"Message\")\n",
    "        # Create a state object to store the conversation history\n",
    "        history_state = gr.State()\n",
    "        # Create a button to send the user's message\n",
    "        btn = gr.Button(value=\"Send\")\n",
    "\n",
    "        # Connect the send button to the chat function\n",
    "        btn.click(chat, inputs=[message, chatbot, history_state], outputs=[message, chatbot, history_state])\n",
    "        # Return the app\n",
    "        return app\n",
    "# ---------------------------------------------------------------------------------------        \n",
    "# Call the launch_chatbot function to start the chatbot interface using Gradio\n",
    "app = get_chatbot_app()\n",
    "app.queue()  # this is to be able to queue multiple requests at once\n",
    "app.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7890dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
