{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ec2fef2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Retrieval Augmented Generation\n",
    "* **Created by:** Eric Martinez\n",
    "* **For:** CSCI 4341\n",
    "* **At:** University of Texas Rio-Grande Valley"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306568dd",
   "metadata": {},
   "source": [
    "## Step 0: Setup your `.env` file locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01461871",
   "metadata": {},
   "source": [
    "Setup your `OPENAI_API_BASE` key and `OPENAI_API_KEY` in a file `.env` in this same folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f07b1",
   "metadata": {},
   "source": [
    "```sh\n",
    "# example .env contents (copy paste this into a .env file)\n",
    "OPENAI_API_BASE=yourapibase\n",
    "OPENAI_API_KEY=yourapikey\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee2dfdb",
   "metadata": {},
   "source": [
    "Install the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeef3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb051ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 1: Create the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aa315a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Use your dataset from the previous homework.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f86b931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile data.json\n",
    "[\n",
    "    {\n",
    "        \"name\": \"Jason's Deli\",\n",
    "        \"address\": \"1604 W University Dr.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Taco Palenque\",\n",
    "        \"address\": \"1414 W University Dr.\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"University Drafthouse\",\n",
    "        \"address\": \"2405 W University Dr. F\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adf330b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Function to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "551920a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_data():\n",
    "    with open(\"data.json\") as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf9c1a",
   "metadata": {},
   "source": [
    "Now actually load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81db1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': \"Jason's Deli\", 'address': '1604 W University Dr.'}, {'name': 'Taco Palenque', 'address': '1414 W University Dr.'}, {'name': 'University Drafthouse', 'address': '2405 W University Dr. F'}]\n"
     ]
    }
   ],
   "source": [
    "data = load_data()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3aec8b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 2: Create Chroma Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a12653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "import os\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "\n",
    "def get_chroma_collection(collection_name):\n",
    "    ## Use this one to save to memory\n",
    "    # chroma_client = chromadb.Client() \n",
    "\n",
    "    ## Use this one to save to disk\n",
    "    chroma_client = chromadb.PersistentClient(path=\".\")\n",
    "\n",
    "    openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "                    api_base=os.getenv(\"OPENAI_API_BASE\"),\n",
    "                    model_name=\"text-embedding-ada-002\"\n",
    "                )\n",
    "\n",
    "    collection = chroma_client.get_or_create_collection(name=collection_name, embedding_function=openai_ef)\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4acd817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = get_chroma_collection(\"food\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20fa3ce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 3: Add Data to Chroma Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91e44070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data_to_collection(data, collection):\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "\n",
    "    for i, restaurant in enumerate(data):\n",
    "        name = restaurant['name']\n",
    "        address = restaurant['address']\n",
    "\n",
    "        # what are we embedding for each restaurant - obviously add to this\n",
    "        embeddable_string = f\"{name}\"\n",
    "        documents.append(embeddable_string)\n",
    "\n",
    "        # lets just store everything we have as metadata\n",
    "        metadatas.append(restaurant)\n",
    "\n",
    "        # lets use the index as the id\n",
    "        ids.append(str(i))\n",
    "\n",
    "    collection.add(\n",
    "        documents=documents,\n",
    "        metadatas=metadatas,\n",
    "        ids=ids\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b97f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_data_to_collection(data, collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca367acf",
   "metadata": {},
   "source": [
    "## Step 4: Query the Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be8392b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_food(query):\n",
    "    metadatas = []\n",
    "    n_results = 2\n",
    "    results = collection.query(query_texts=[query], n_results=2)\n",
    "    \n",
    "    for i in range(n_results):\n",
    "        metadatas.append(results[\"metadatas\"][0][i])\n",
    "        \n",
    "    return metadatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1b67a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'address': '1414 W University Dr.', 'name': 'Taco Palenque'}, {'address': '1604 W University Dr.', 'name': \"Jason's Deli\"}]\n"
     ]
    }
   ],
   "source": [
    "results = search_food(\"fajita\")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bbae61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 5: Build the Gradio UI for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07784b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "Running on public URL: https://62c91ef60d35887278.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://62c91ef60d35887278.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "import gradio as gr\n",
    "import openai\n",
    "import re\n",
    "\n",
    "# ---------------------------------------------------------------------------------------\n",
    "def needs_tool(response):\n",
    "    return \"Tool:\" in response\n",
    "\n",
    "def extract_call(string):\n",
    "    # regex pattern\n",
    "    pattern = r'Tool: (\\w+)\\((.*?)\\)'\n",
    "    match = re.search(pattern, string)\n",
    "    if match:\n",
    "        tool_name = match.group(1)\n",
    "        parameters = match.group(2).replace('\"', '').split(', ')\n",
    "        return tool_name, parameters\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "def invoke_tool(response):\n",
    "    tool_name, parameters = extract_call(response)\n",
    "    \n",
    "    if tool_name == \"search_food\":\n",
    "        tool_result = search_food(*parameters)\n",
    "        \n",
    "    return tool_result\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Define a function to get the AI's reply using the OpenAI API\n",
    "def get_ai_reply(message, model=\"gpt-3.5-turbo\", system_message=None, temperature=0, message_history=[]):\n",
    "    # Initialize the messages list\n",
    "    messages = []\n",
    "    \n",
    "    # Add the system message to the messages list\n",
    "    if system_message is not None:\n",
    "        messages += [{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "    # Add the message history to the messages list\n",
    "    if message_history is not None:\n",
    "        messages += message_history\n",
    "    \n",
    "    if message is not None:\n",
    "        # Add the user's message to the messages list\n",
    "        messages += [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    # Make an API call to the OpenAI ChatCompletion endpoint with the model and messages\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    # Extract and return the AI's response from the API response\n",
    "    return completion.choices[0].message.content.strip()\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Define a function to handle the chat interaction with the AI model\n",
    "def chat(message, chatbot_messages, history_state):\n",
    "    # Initialize chatbot_messages and history_state if they are not provided\n",
    "    chatbot_messages = chatbot_messages or []\n",
    "    history_state = history_state or []\n",
    "    \n",
    "    # Try to get the AI's reply using the get_ai_reply function\n",
    "    try:\n",
    "        prompt = \"\"\"\n",
    "        You are a helpful expert restaurant assistant named Jarvis.\n",
    "\n",
    "        Your knowledge cut-off is: September 2021\n",
    "        Today's date: October 18, 2023\n",
    "\n",
    "        ## Tools\n",
    "\n",
    "        You have access to the following tools:\n",
    "        - search_food(query): Tool to lookup food based close to the user based on their query. Use this tools when the user is looking for food suggestions near them. You don't need to know the user's location, the tool doesn't need it. Be careful, the tool will return the top results in the database but not all of them may be relevant. Use your judgement when answering the user's question. Example: search_food(\"place to get a good burger and craft beer\")\n",
    "\n",
    "        ## Tool Rules\n",
    "\n",
    "        When the user asks a question that can be answered by using a tool, you MUST do so. Do not answer from your training data.\n",
    "\n",
    "        ## Using Tools\n",
    "\n",
    "        To use a tool, reply with the following prefix \"Tool: \" then append the tool call (like a function call). \n",
    "\n",
    "        Behind the scenes, your software will pickup that you want to invoke a tool and invoke it for you and provide you the response.\n",
    "\n",
    "        ## Using Tool Responses\n",
    "\n",
    "        Answer the user's question using the response from the tool. Feel free to make it conversational. \n",
    "        \"\"\"\n",
    "        ai_reply = get_ai_reply(message, model=\"gpt-3.5-turbo\", system_message=prompt.strip(), message_history=history_state)\n",
    "            \n",
    "        # Append the user's message and the AI's reply to the history_state list\n",
    "        history_state.append({\"role\": \"user\", \"content\": message})\n",
    "        history_state.append({\"role\": \"assistant\", \"content\": ai_reply})\n",
    "        \n",
    "        while(needs_tool(ai_reply)):\n",
    "            tool_result = invoke_tool(ai_reply)\n",
    "            history_state.append({\"role\": \"assistant\", \"content\": f\"Tool Result: {tool_result}\"})\n",
    "            ai_reply = get_ai_reply(None, model=\"gpt-3.5-turbo\", system_message=prompt.strip(), message_history=history_state)\n",
    "            history_state.append({\"role\": \"assistant\", \"content\": ai_reply})\n",
    "            \n",
    "        # Append the user's message and the AI's reply to the chatbot_messages list for the UI\n",
    "        chatbot_messages.append((message, ai_reply))\n",
    "\n",
    "        # Return None (empty out the user's message textbox), the updated chatbot_messages, and the updated history_state\n",
    "    except Exception as e:\n",
    "        # If an error occurs, raise a Gradio error\n",
    "        raise gr.Error(e)\n",
    "        \n",
    "    return None, chatbot_messages, history_state\n",
    "\n",
    "# Define a function to launch the chatbot interface using Gradio\n",
    "def get_chatbot_app():\n",
    "    # Create the Gradio interface using the Blocks layout\n",
    "    with gr.Blocks() as app:\n",
    "        # Create a chatbot interface for the conversation\n",
    "        chatbot = gr.Chatbot(label=\"Conversation\")\n",
    "        # Create a textbox for the user's message\n",
    "        message = gr.Textbox(label=\"Message\")\n",
    "        # Create a state object to store the conversation history\n",
    "        history_state = gr.State()\n",
    "        # Create a button to send the user's message\n",
    "        btn = gr.Button(value=\"Send\")\n",
    "\n",
    "        # Connect the send button to the chat function\n",
    "        btn.click(chat, inputs=[message, chatbot, history_state], outputs=[message, chatbot, history_state])\n",
    "        # Return the app\n",
    "        return app\n",
    "# ---------------------------------------------------------------------------------------        \n",
    "# Call the launch_chatbot function to start the chatbot interface using Gradio\n",
    "app = get_chatbot_app()\n",
    "app.queue()  # this is to be able to queue multiple requests at once\n",
    "app.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d071d0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
